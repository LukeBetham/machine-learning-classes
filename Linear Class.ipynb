{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T15:59:28.859556Z",
     "start_time": "2020-01-10T15:59:27.036063Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries for class\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:00:40.749127Z",
     "start_time": "2020-01-10T16:00:40.508262Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sklearn models needed for class\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T13:47:14.828869Z",
     "start_time": "2020-01-11T13:47:14.793383Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class full_linear:\n",
    "    \"\"\"A class which automatically does all of the linear regression for you. \n",
    "    Defaults are test size 0.15, folds=6, n_alphas = 66 for lasso, logspace =66 for ridge, and l1 = 20 steps\n",
    "    Created by LukeBetham\"\"\"        \n",
    "    \n",
    "    def __init__(self, X, y, test_size=0.15, folds=6, shuffle=True):\n",
    "         \n",
    "        #Set up the KFolds\n",
    "        self.folds = folds\n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "        #Add option for train-test if selected\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.test = test_size\n",
    "        if self.test != 0:\n",
    "            self.X, self.X_test, self.y, self.y_test = train_test_split(X, y, test_size=self.test, random_state=66)\n",
    "        \n",
    "        #Standardise the data\n",
    "        scaler = StandardScaler()\n",
    "        self.X = pd.DataFrame(scaler.fit_transform(self.X), columns=X.columns)\n",
    "        if self.test != 0:\n",
    "            self.X_test = pd.DataFrame(scaler.transform(self.X_test), columns=X.columns)\n",
    "        \n",
    "        # Set up linear Regresssion       \n",
    "        self.model = LinearRegression()\n",
    "        self.model_fitter()\n",
    "        print(\"Linear Regression Test\\nModel R2 Score:\",self.score,\"\\nModel Test Score:\",self.test_score,\n",
    "             '\\nCV Fold Score:',self.cv_score)\n",
    "        self.coefs()\n",
    "        print(\"\\nUse .ridge(), .lasso() and .elastic_net() to run full regularisation tests.\",\n",
    "              \"\\nRun .coefs(n) to show n top coefficients and .df to return the coef dataframe.\",\n",
    "              \"\\nRun .resid_plot() to plot residuals and .resid_df to return dataframe\")\n",
    "        \n",
    "        #show coefs   \n",
    "    def coefs(self,show=6):\n",
    "        df = pd.DataFrame(self.coef_)\n",
    "        df.columns = [\"coefs\"]\n",
    "        df['abs coef']=abs(df['coefs'])\n",
    "        df['columns']=self.X.columns\n",
    "        self.df = df.sort_values(by='abs coef',ascending=False)\n",
    "        print(\"Highest Coefs:\\n\",self.df.head(show))\n",
    "        print(\"Amount of dropped variables:\",len(df['coefs'][df['coefs']==0]),\"\\nPercent of X variables dropped\",\n",
    "              round(len(df['coefs'][df['coefs']==0])/len(df['coefs'])*100),'%')\n",
    "\n",
    "        # Ridge regularisation\n",
    "    def ridge(self, lower= -10, upper=10, log = 66):\n",
    "        model = RidgeCV(np.logspace(lower,upper,log),cv=KFold(self.folds, shuffle=self.shuffle, random_state=6))\n",
    "        model.fit(self.X,self.y)\n",
    "        self.alpha_ = model.alpha_\n",
    "        self.model = Ridge(alpha=self.alpha_)\n",
    "        self.model_fitter()\n",
    "        print(\"Ridge Regularisation Test\\nAlpha log range # used for RidgeCV fit: np.logspace(\",lower,upper,log,\")\\nAlpha:\",self.alpha_,\n",
    "              \"\\nModel R2 Score:\",self.score,\"\\nModel Test Score:\",self.test_score,\n",
    "              '\\nCV Fold Score:',self.cv_score)\n",
    "        self.coefs()\n",
    "        \n",
    "        #Lasso regularisation\n",
    "    def lasso(self, n_alphas = 66):\n",
    "        model = LassoCV(n_alphas=n_alphas,cv=KFold(self.folds, shuffle=self.shuffle, random_state=6))\n",
    "        model.fit(self.X,self.y)\n",
    "        self.alpha_ = model.alpha_\n",
    "        self.model = Lasso(alpha=self.alpha_)\n",
    "        self.model_fitter()\n",
    "        print(\"Lasso Regularisation Test\\nNumber of alphas used for LassoCV fit:\",n_alphas,\"\\nAlpha output:\",self.alpha_,\n",
    "              \"\\nModel R2 Score:\",self.score,\"\\nModel Test Score:\",self.test_score,\n",
    "              '\\nCV Fold Score:',self.cv_score)\n",
    "        self.coefs()\n",
    "        \n",
    "        #elastic_net regularisation\n",
    "    def elastic_net(self, n_alphas = 66,l1 = 20):\n",
    "        model = ElasticNetCV(l1_ratio=np.linspace(0.0001,1,l1), n_alphas=n_alphas, cv=KFold(self.folds,shuffle=self.shuffle, random_state=6))\n",
    "        model.fit(self.X,self.y)\n",
    "        self.alpha_ = model.alpha_\n",
    "        self.l1_ratio_ = model.l1_ratio_\n",
    "        self.model = ElasticNet(alpha=self.alpha_,l1_ratio=self.l1_ratio_)\n",
    "        self.model_fitter()\n",
    "        print(\"Elastic Net Regularisation Test\\nNumber of alphas used for CV fit:\",n_alphas,\"\\nAlpha output:\",self.alpha_,\n",
    "              '\\nl1 iterations: np.linspace( 0.0001, 1,',l1,\")\\nl1 ratio value:\",self.l1_ratio_,\n",
    "              \"\\nModel R2 Score:\",self.score,\"\\nModel Test Score:\",self.test_score,'\\nCV Fold Score:',self.cv_score)\n",
    "        self.coefs()\n",
    "        \n",
    "    def model_fitter(self):\n",
    "        self.model.fit(self.X, self.y)\n",
    "        self.y_pred = self.model.predict(self.X)\n",
    "        self.cv_score = (np.mean(cross_val_score(self.model, self.X, self.y, cv=KFold(self.folds, shuffle=self.shuffle, random_state=6))))\n",
    "        self.score = self.model.score(self.X, self.y)\n",
    "        self.coef_ = self.model.coef_\n",
    "        self.intercept_ = self.model.intercept_\n",
    "        self.resids = self.y - self.y_pred\n",
    "        self.resid_df = pd.DataFrame({'resids':self.resids, 'y_pred':self.y_pred, 'y':self.y},index=list(self.y.index))\n",
    "        if self.test != 0:\n",
    "            self.test_score = self.model.score(self.X_test, self.y_test)\n",
    "        else:\n",
    "            self.test_score = \"None\"\n",
    "        \n",
    "#     this isn't working yet\n",
    "    def resid_plot(self):\n",
    "        f, ax = plt.subplots(figsize=(8,8))\n",
    "        ax = sns.scatterplot(self.y_pred,self.y,color=\"indigo\");\n",
    "        ax = sns.lineplot(x=(0,self.y.max()),y=(0,self.y.max()),color='thistle');\n",
    "        ax = plt.xlabel(\"Predicted Y Values\")\n",
    "        ax = plt.ylabel(\"Actual Y Values\")\n",
    "        return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe = pd.read_csv('resource-datasets/kobe_bryant/kobe_superwide_games.csv')\n",
    "y = kobe.pop('SHOTS_MADE')\n",
    "X = kobe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T14:32:37.127042Z",
     "start_time": "2020-01-11T14:32:36.149082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Test\n",
      "Model R2 Score: 0.7835726764598443 \n",
      "Model Test Score: -5.36452230583681e+25 \n",
      "CV Fold Score: -1.7854337350623109e+28\n",
      "Highest Coefs:\n",
      "             coefs      abs coef                            columns\n",
      "262  5.824193e+13  5.824193e+13        SEASON_OPPONENT:mil:2001-02\n",
      "538 -4.902604e+13  4.902604e+13                     SEASON:2004-05\n",
      "549 -4.673741e+13  4.673741e+13                     SEASON:2015-16\n",
      "532 -4.433678e+13  4.433678e+13                     SEASON:1998-99\n",
      "557  4.291533e+13  4.291533e+13            SHOT_ZONE_RANGE:24+_ft.\n",
      "561 -4.277801e+13  4.277801e+13  SHOT_ZONE_BASIC:above_the_break_3\n",
      "Amount of dropped variables: 1 \n",
      "Percent of X variables dropped 0 %\n",
      "\n",
      "Use .ridge(), .lasso() and .elastic_net() to run full regularisation tests. \n",
      "Run .coefs(n) to show n top coefficients and .df to return the coef dataframe. \n",
      "Run .resid_plot() to plot residuals and .resid_df to return dataframe\n"
     ]
    }
   ],
   "source": [
    "nm = full_linear(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T13:47:24.952758Z",
     "start_time": "2020-01-11T13:47:24.938129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method full_linear.resid_plot of <__main__.full_linear object at 0x1a19348128>>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm.resid_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:35:56.079563Z",
     "start_time": "2020-01-10T16:35:51.638328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukebetham/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3891309001583068, tolerance: 1.3287666987487972\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regularisation Test\n",
      "Number of alphas used for LassoCV fit: 66 \n",
      "Alpha output: 0.10960240490911179 \n",
      "Model R2 Score: 0.6861277829847843 \n",
      "Model Test Score: 0.6141667121969712 \n",
      "CV Fold Score: 0.6499534123048463\n",
      "Highest Coefs:\n",
      "         coefs  abs coef                            columns\n",
      "579  1.288412  1.288412       COMBINED_SHOT_TYPE:jump_shot\n",
      "574  0.919108  0.919108           SHOT_TYPE:2pt_field_goal\n",
      "566  0.556024  0.556024    SHOT_ZONE_BASIC:restricted_area\n",
      "577  0.325345  0.325345            COMBINED_SHOT_TYPE:dunk\n",
      "611 -0.234934  0.234934              ACTION_TYPE:jump_shot\n",
      "561  0.200475  0.200475  SHOT_ZONE_BASIC:above_the_break_3\n",
      "Amount of dropped variables: 587 \n",
      "Percent of X variables dropped 91 %\n"
     ]
    }
   ],
   "source": [
    "nm.lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:36:07.565169Z",
     "start_time": "2020-01-10T16:36:00.289367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regularisation Test\n",
      "Alpha log range # used for RidgeCV fit: np.logspace( -5 5 66 )\n",
      "Alpha: 1425.1026703030022 \n",
      "Model R2 Score: 0.765379128249869 \n",
      "Model Test Score: 0.5868594332279788 \n",
      "CV Fold Score: 0.6233122944049794\n",
      "Highest Coefs:\n",
      "         coefs  abs coef                       columns\n",
      "574  0.244078  0.244078      SHOT_TYPE:2pt_field_goal\n",
      "579  0.219806  0.219806  COMBINED_SHOT_TYPE:jump_shot\n",
      "582  0.214363  0.214363             SECONDS_REMAINING\n",
      "569  0.213853  0.213853      SHOT_ZONE_AREA:center(c)\n",
      "584  0.206771  0.206771                        PERIOD\n",
      "577  0.197239  0.197239       COMBINED_SHOT_TYPE:dunk\n",
      "Amount of dropped variables: 21 \n",
      "Percent of X variables dropped 3 %\n"
     ]
    }
   ],
   "source": [
    "nm.ridge(-5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T16:37:09.642059Z",
     "start_time": "2020-01-10T16:36:13.165649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukebetham/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3265560839313366, tolerance: 1.2853659287776709\n",
      "  tol, rng, random, positive)\n",
      "/Users/lukebetham/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3891309001583068, tolerance: 1.3287666987487972\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net Regularisation Test\n",
      "Number of alphas used for CV fit: 66 \n",
      "Alpha output: 0.10960240490911179 \n",
      "l1 iterations: np.linspace( 0.0001, 1, 20 )\n",
      "l1 ratio value: 1.0 \n",
      "Model R2 Score: 0.6861277829847843 \n",
      "Model Test Score: 0.6141667121969712 \n",
      "CV Fold Score: 0.6499534123048463\n",
      "Highest Coefs:\n",
      "         coefs  abs coef                            columns\n",
      "579  1.288412  1.288412       COMBINED_SHOT_TYPE:jump_shot\n",
      "574  0.919108  0.919108           SHOT_TYPE:2pt_field_goal\n",
      "566  0.556024  0.556024    SHOT_ZONE_BASIC:restricted_area\n",
      "577  0.325345  0.325345            COMBINED_SHOT_TYPE:dunk\n",
      "611 -0.234934  0.234934              ACTION_TYPE:jump_shot\n",
      "561  0.200475  0.200475  SHOT_ZONE_BASIC:above_the_break_3\n",
      "Amount of dropped variables: 587 \n",
      "Percent of X variables dropped 91 %\n"
     ]
    }
   ],
   "source": [
    "nm.elastic_net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "362px",
    "left": "1060px",
    "right": "20px",
    "top": "120px",
    "width": "360px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
